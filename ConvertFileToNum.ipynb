{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3qKzKgCn4IrL0TFRT6tT5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oyinig/African-AI-Foundation/blob/main/ConvertFileToNum.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjoJCpG-Mo5k",
        "outputId": "200c72ca-07b5-4405-cecb-6812e4f84551"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m120.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.31.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "hXmLWrzG1Y3M"
      },
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "import shutil\n",
        "import os\n",
        "import io\n",
        "from transformers import Wav2Vec2FeatureExtractor\n",
        "import torchaudio\n",
        "from torchaudio.transforms import Resample\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert an image in the content folder to numbers"
      ],
      "metadata": {
        "id": "ondWhC6CLjpt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def image_to_matrix():\n",
        "    image = Image.open('/content/images/image.jpeg')\n",
        "    # Convert the image to grayscale\n",
        "    image_gray = image.convert('L')\n",
        "    # Convert the grayscale image to a numpy array\n",
        "    matrix = np.array(image_gray)\n",
        "    np.savetxt(\"/content/image_data.csv\", matrix)\n",
        "    return matrix\n",
        "\n",
        "image_to_matrix()"
      ],
      "metadata": {
        "id": "b4Fj8CR81era",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "093f25c3-3eeb-43b3-8c76-aa2e5cc9c5f2"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[255, 255, 255, ..., 255, 255, 255],\n",
              "       [255, 255, 255, ..., 255, 255, 255],\n",
              "       [255, 255, 255, ..., 255, 255, 255],\n",
              "       ...,\n",
              "       [255, 255, 255, ..., 255, 255, 255],\n",
              "       [255, 255, 255, ..., 255, 255, 255],\n",
              "       [255, 255, 255, ..., 255, 255, 255]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_audio_features():\n",
        "    audio_file = '/content/audio/sample-3s.mp3'\n",
        "\n",
        "    waveform, original_sample_rate = torchaudio.load(audio_file)\n",
        "\n",
        "    # Resample the audio waveform to 16000 Hz\n",
        "    resample_transform = Resample(orig_freq=original_sample_rate, new_freq=16000)\n",
        "    resampled_waveform = resample_transform(waveform)\n",
        "\n",
        "    # Initialize Wav2Vec2 feature extractor\n",
        "    feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "\n",
        "    # Extract audio features\n",
        "    features = feature_extractor(resampled_waveform, sampling_rate=16000, return_tensors=\"pt\")\n",
        "    np.save('/content/extracted_audio_features.npy', features.input_values.numpy())\n",
        "    return features\n",
        "\n",
        "extract_audio_features()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1125UlrVKB9n",
        "outputId": "faca89d8-5af4-4344-ab88-ec4c27f22138"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_values': tensor([[[-0.2358,  0.0660,  0.2489,  ..., -0.2437,  0.0678,  0.2143],\n",
              "         [-0.2358,  0.0660,  0.2489,  ..., -0.2437,  0.0678,  0.2143]]])}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2wazvA1qLhy-"
      }
    }
  ]
}